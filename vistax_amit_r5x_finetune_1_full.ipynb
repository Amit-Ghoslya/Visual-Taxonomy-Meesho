{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e09c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb94855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "category_attributes = pd.read_parquet('category_attributes.parquet')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df = train_df.drop(columns=['len'])\n",
    "\n",
    "# Preprocess category-to-attributes dictionary\n",
    "category_to_attributes = {\n",
    "    row['Category']: row['Attribute_list']\n",
    "    for _, row in category_attributes.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f847dba7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\AppData\\Local\\Temp\\ipykernel_2372\\1896303643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[attr_col] = df[attr_col].apply(lambda x: random.choice(non_na_values) if pd.isna(x) else x)\n",
      "C:\\Users\\Ghosl\\AppData\\Local\\Temp\\ipykernel_2372\\1896303643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[attr_col] = df[attr_col].apply(lambda x: random.choice(non_na_values) if pd.isna(x) else x)\n",
      "C:\\Users\\Ghosl\\AppData\\Local\\Temp\\ipykernel_2372\\1896303643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[attr_col] = df[attr_col].apply(lambda x: random.choice(non_na_values) if pd.isna(x) else x)\n",
      "C:\\Users\\Ghosl\\AppData\\Local\\Temp\\ipykernel_2372\\1896303643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[attr_col] = df[attr_col].apply(lambda x: random.choice(non_na_values) if pd.isna(x) else x)\n",
      "C:\\Users\\Ghosl\\AppData\\Local\\Temp\\ipykernel_2372\\1896303643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[attr_col] = df[attr_col].apply(lambda x: random.choice(non_na_values) if pd.isna(x) else x)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with random imputation\n",
    "def random_impute(df, attribute_positions):\n",
    "    for attr_col in attribute_positions.keys():\n",
    "        if df[attr_col].isna().sum() > 0:\n",
    "            non_na_values = df[attr_col].dropna().unique()\n",
    "            df[attr_col] = df[attr_col].apply(lambda x: random.choice(non_na_values) if pd.isna(x) else x)\n",
    "    return df\n",
    "\n",
    "# Apply random imputation for each category\n",
    "for _, row in category_attributes.iterrows():\n",
    "    category = row['Category']\n",
    "    attributes = row['Attribute_list']\n",
    "    attribute_positions = {f'attr_{i+1}': attr_name for i, attr_name in enumerate(attributes)}\n",
    "    category_df = train_df[train_df['Category'] == category]\n",
    "    filled_category_df = random_impute(category_df, attribute_positions)\n",
    "    train_df.update(filled_category_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc25517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace irrelevant attributes with 'DV' and encode attributes\n",
    "for i in range(1, 11):\n",
    "    attr_col = f'attr_{i}'\n",
    "    train_df[attr_col].fillna('DV', inplace=True)\n",
    "train_df['id'] = train_df['id'].astype('int64')\n",
    "\n",
    "encoders = {}\n",
    "for col in [f'attr_{i}' for i in range(1, 11)]:\n",
    "    encoder = LabelEncoder()\n",
    "    train_df[col] = encoder.fit_transform(train_df[col].astype(str))\n",
    "    encoders[col] = encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37c1ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom ResNet-50 model with multi-layer feature extraction\n",
    "def create_resnet_feature_extractor(input_shape=(256, 256, 3), reduced_dim=512, fine_tune_at_layer=100):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Fine-tune from an earlier layer to capture more details\n",
    "    for layer in base_model.layers[:fine_tune_at_layer]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Extract features from both final and intermediate layers\n",
    "    intermediate_layer_model = Model(inputs=base_model.input, outputs=[\n",
    "        base_model.get_layer(\"conv4_block1_out\").output,  # Intermediate layer\n",
    "        base_model.get_layer(\"conv5_block3_out\").output   # Final ResNet layer\n",
    "    ])\n",
    "\n",
    "    # Add pooling and custom dense layers\n",
    "    intermediate_output, final_output = intermediate_layer_model.output\n",
    "    intermediate_output = GlobalAveragePooling2D()(intermediate_output)\n",
    "    final_output = GlobalAveragePooling2D()(final_output)\n",
    "    \n",
    "    # Concatenate intermediate and final layer outputs\n",
    "    concatenated_output = tf.keras.layers.Concatenate()([intermediate_output, final_output])\n",
    "    x = Dense(reduced_dim, activation='relu')(concatenated_output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "# Initialize feature extractor with multi-layer features\n",
    "feature_extractor = create_resnet_feature_extractor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd4cf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from images\n",
    "def extract_resnet_features(img_path, target_size=(256, 256)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    features = feature_extractor.predict(img_array)\n",
    "    return features.flatten()\n",
    "\n",
    "# Batch-wise image feature extraction\n",
    "def extract_image_features_batch(df, img_dir, output_path, feature_extractor):\n",
    "    features = {}\n",
    "    for img_id in df['id']:\n",
    "        img_path = os.path.join(img_dir, f\"{int(img_id):06}.jpg\")\n",
    "        if os.path.exists(img_path):\n",
    "            features[img_id] = extract_resnet_features(img_path)\n",
    "    features_df = pd.DataFrame.from_dict(features, orient='index')\n",
    "    features_df.to_csv(output_path)\n",
    "    return features_df\n",
    "\n",
    "# # Function to extract features from images\n",
    "# def extract_resnet_features(img_path, feature_extractor, target_size=(256, 256)):\n",
    "#     img = image.load_img(img_path, target_size=target_size)\n",
    "#     img_array = image.img_to_array(img)\n",
    "#     img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "#     features = feature_extractor.predict(img_array)\n",
    "#     return features.flatten()\n",
    "\n",
    "# # Batch-wise image feature extraction with progress tracking\n",
    "# def extract_image_features_batch(df, img_dir, output_path, feature_extractor):\n",
    "#     features = {}\n",
    "#     for img_id in tqdm(df['id'], desc=\"Extracting Features\"):\n",
    "#         img_path = os.path.join(img_dir, f\"{int(img_id):06}.jpg\")\n",
    "#         if os.path.exists(img_path):\n",
    "#             features[img_id] = extract_resnet_features(img_path, feature_extractor)\n",
    "#     features_df = pd.DataFrame.from_dict(features, orient='index')\n",
    "#     features_df.to_csv(output_path)\n",
    "#     return features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c65aa800",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_path = 'train_image_features_multilayer.csv'\n",
    "\n",
    "if not os.path.exists(train_features_path):\n",
    "    train_img_features_df = extract_image_features_batch(train_df, 'train_images', train_features_path, feature_extractor)\n",
    "else:\n",
    "    train_img_features_df = pd.read_csv(train_features_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a754955",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689740</td>\n",
       "      <td>0.865177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624610</td>\n",
       "      <td>0.018495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452350</td>\n",
       "      <td>1.064275</td>\n",
       "      <td>1.288730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.001462</td>\n",
       "      <td>1.316511</td>\n",
       "      <td>0.479237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.829285</td>\n",
       "      <td>1.066783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.502917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.362627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462133</td>\n",
       "      <td>1.147076</td>\n",
       "      <td>1.244628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.971780</td>\n",
       "      <td>1.202177</td>\n",
       "      <td>0.416088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823437</td>\n",
       "      <td>1.120516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025263</td>\n",
       "      <td>0.449964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458623</td>\n",
       "      <td>1.199253</td>\n",
       "      <td>1.273217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.971126</td>\n",
       "      <td>1.201153</td>\n",
       "      <td>0.351132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920630</td>\n",
       "      <td>1.118722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062921</td>\n",
       "      <td>0.395592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.491309</td>\n",
       "      <td>1.184932</td>\n",
       "      <td>1.263458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.981495</td>\n",
       "      <td>1.223018</td>\n",
       "      <td>0.425713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.841864</td>\n",
       "      <td>1.035506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028875</td>\n",
       "      <td>0.489829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.443651</td>\n",
       "      <td>1.151554</td>\n",
       "      <td>1.247658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.969832</td>\n",
       "      <td>1.186001</td>\n",
       "      <td>0.405526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70374</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643625</td>\n",
       "      <td>0.967281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615319</td>\n",
       "      <td>0.048219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517153</td>\n",
       "      <td>1.073927</td>\n",
       "      <td>1.298169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.939384</td>\n",
       "      <td>1.341032</td>\n",
       "      <td>0.420804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70375</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712026</td>\n",
       "      <td>1.158837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478972</td>\n",
       "      <td>0.444187</td>\n",
       "      <td>0.240014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.672450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611231</td>\n",
       "      <td>1.466686</td>\n",
       "      <td>1.379860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.798207</td>\n",
       "      <td>1.186979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70376</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867143</td>\n",
       "      <td>1.032658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573031</td>\n",
       "      <td>0.086450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436562</td>\n",
       "      <td>1.088179</td>\n",
       "      <td>1.338972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.917899</td>\n",
       "      <td>1.314930</td>\n",
       "      <td>0.400409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70377</th>\n",
       "      <td>0.011309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756985</td>\n",
       "      <td>0.985720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.574852</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427995</td>\n",
       "      <td>1.107717</td>\n",
       "      <td>1.356371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000670</td>\n",
       "      <td>1.364415</td>\n",
       "      <td>0.464064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70378</th>\n",
       "      <td>0.016683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.672184</td>\n",
       "      <td>0.894369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461729</td>\n",
       "      <td>1.022914</td>\n",
       "      <td>1.358872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.977299</td>\n",
       "      <td>1.347937</td>\n",
       "      <td>0.464804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70213 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1    2         3         4    5         6         7  \\\n",
       "0      0.022255  0.0  0.0  0.689740  0.865177  0.0  0.000000  0.624610   \n",
       "1      0.000000  0.0  0.0  0.829285  1.066783  0.0  0.003637  0.502917   \n",
       "2      0.000000  0.0  0.0  0.823437  1.120516  0.0  0.025263  0.449964   \n",
       "3      0.000000  0.0  0.0  0.920630  1.118722  0.0  0.062921  0.395592   \n",
       "4      0.000000  0.0  0.0  0.841864  1.035506  0.0  0.028875  0.489829   \n",
       "...         ...  ...  ...       ...       ...  ...       ...       ...   \n",
       "70374  0.000000  0.0  0.0  0.643625  0.967281  0.0  0.000000  0.615319   \n",
       "70375  0.000000  0.0  0.0  0.712026  1.158837  0.0  0.478972  0.444187   \n",
       "70376  0.000000  0.0  0.0  0.867143  1.032658  0.0  0.000000  0.573031   \n",
       "70377  0.011309  0.0  0.0  0.756985  0.985720  0.0  0.000000  0.574852   \n",
       "70378  0.016683  0.0  0.0  0.672184  0.894369  0.0  0.000000  0.614564   \n",
       "\n",
       "              8    9  ...  502       503  504       505       506       507  \\\n",
       "0      0.018495  0.0  ...  0.0  0.232569  0.0  0.452350  1.064275  1.288730   \n",
       "1      0.000000  0.0  ...  0.0  0.362627  0.0  0.462133  1.147076  1.244628   \n",
       "2      0.000000  0.0  ...  0.0  0.422802  0.0  0.458623  1.199253  1.273217   \n",
       "3      0.000000  0.0  ...  0.0  0.429789  0.0  0.491309  1.184932  1.263458   \n",
       "4      0.000000  0.0  ...  0.0  0.369076  0.0  0.443651  1.151554  1.247658   \n",
       "...         ...  ...  ...  ...       ...  ...       ...       ...       ...   \n",
       "70374  0.048219  0.0  ...  0.0  0.302742  0.0  0.517153  1.073927  1.298169   \n",
       "70375  0.240014  0.0  ...  0.0  0.672450  0.0  0.611231  1.466686  1.379860   \n",
       "70376  0.086450  0.0  ...  0.0  0.455007  0.0  0.436562  1.088179  1.338972   \n",
       "70377  0.046948  0.0  ...  0.0  0.297944  0.0  0.427995  1.107717  1.356371   \n",
       "70378  0.000000  0.0  ...  0.0  0.274836  0.0  0.461729  1.022914  1.358872   \n",
       "\n",
       "       508       509       510       511  \n",
       "0      0.0  2.001462  1.316511  0.479237  \n",
       "1      0.0  1.971780  1.202177  0.416088  \n",
       "2      0.0  1.971126  1.201153  0.351132  \n",
       "3      0.0  1.981495  1.223018  0.425713  \n",
       "4      0.0  1.969832  1.186001  0.405526  \n",
       "...    ...       ...       ...       ...  \n",
       "70374  0.0  1.939384  1.341032  0.420804  \n",
       "70375  0.0  1.798207  1.186979  0.000000  \n",
       "70376  0.0  1.917899  1.314930  0.400409  \n",
       "70377  0.0  2.000670  1.364415  0.464064  \n",
       "70378  0.0  1.977299  1.347937  0.464804  \n",
       "\n",
       "[70213 rows x 512 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1d765aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge image features with train and test data\n",
    "train_df = train_df.merge(train_img_features_df, left_on='id', right_index=True)\n",
    "\n",
    "\n",
    "# Prepare data for XGBoost\n",
    "train_df['Category'] = train_df['Category'].astype('category').cat.codes\n",
    "X = train_df.drop(columns=['id', 'attr_1', 'attr_2', 'attr_3', 'attr_4', 'attr_5', \n",
    "                           'attr_6', 'attr_7', 'attr_8', 'attr_9', 'attr_10'])\n",
    "y_attributes = train_df[['attr_1', 'attr_2', 'attr_3', 'attr_4', 'attr_5', \n",
    "                         'attr_6', 'attr_7', 'attr_8', 'attr_9', 'attr_10']]\n",
    "\n",
    "# Split data for training and validation\n",
    "X_train, X_val, y_train_attrs, y_val_attrs = train_test_split(X, y_attributes, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54486f16",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33510</th>\n",
       "      <td>4</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.844502</td>\n",
       "      <td>0.924122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.362035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467673</td>\n",
       "      <td>1.165974</td>\n",
       "      <td>1.293850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.014301</td>\n",
       "      <td>1.277717</td>\n",
       "      <td>0.469044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731659</td>\n",
       "      <td>0.939519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484815</td>\n",
       "      <td>0.039116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.508091</td>\n",
       "      <td>1.130859</td>\n",
       "      <td>1.194992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.950154</td>\n",
       "      <td>1.215159</td>\n",
       "      <td>0.431288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41888</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.977552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038242</td>\n",
       "      <td>0.575311</td>\n",
       "      <td>0.098381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472730</td>\n",
       "      <td>1.122290</td>\n",
       "      <td>1.296171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.944820</td>\n",
       "      <td>1.318709</td>\n",
       "      <td>0.374003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64755</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>1.042818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051466</td>\n",
       "      <td>0.603697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470313</td>\n",
       "      <td>1.071408</td>\n",
       "      <td>1.411013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.844043</td>\n",
       "      <td>1.418078</td>\n",
       "      <td>0.320643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43956</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692414</td>\n",
       "      <td>0.909816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633609</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474872</td>\n",
       "      <td>1.126492</td>\n",
       "      <td>1.340509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.955878</td>\n",
       "      <td>1.339561</td>\n",
       "      <td>0.333649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>4</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>0.964591</td>\n",
       "      <td>1.173508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140219</td>\n",
       "      <td>0.314867</td>\n",
       "      <td>0.050530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472412</td>\n",
       "      <td>1.183986</td>\n",
       "      <td>1.249412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.956842</td>\n",
       "      <td>1.329571</td>\n",
       "      <td>0.390479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952198</td>\n",
       "      <td>1.008503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337828</td>\n",
       "      <td>0.406006</td>\n",
       "      <td>0.035491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459295</td>\n",
       "      <td>1.307488</td>\n",
       "      <td>1.178103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.797342</td>\n",
       "      <td>1.186611</td>\n",
       "      <td>0.166288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>3</td>\n",
       "      <td>0.041388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.848586</td>\n",
       "      <td>1.039537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502696</td>\n",
       "      <td>0.079170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459634</td>\n",
       "      <td>1.081609</td>\n",
       "      <td>1.255658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.942527</td>\n",
       "      <td>1.300690</td>\n",
       "      <td>0.468613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818041</td>\n",
       "      <td>1.054909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144149</td>\n",
       "      <td>0.560007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413958</td>\n",
       "      <td>1.213924</td>\n",
       "      <td>1.369703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.892915</td>\n",
       "      <td>1.289477</td>\n",
       "      <td>0.283148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736923</td>\n",
       "      <td>1.005885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.598949</td>\n",
       "      <td>0.164870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563077</td>\n",
       "      <td>1.221669</td>\n",
       "      <td>1.255569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.987585</td>\n",
       "      <td>1.197671</td>\n",
       "      <td>0.277812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56170 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category         0    1         2         3         4    5         6  \\\n",
       "33510         4  0.007645  0.0  0.000000  0.844502  0.924122  0.0  0.000000   \n",
       "12486         2  0.005848  0.0  0.000000  0.731659  0.939519  0.0  0.000000   \n",
       "41888         4  0.043288  0.0  0.000000  0.791480  0.977552  0.0  0.038242   \n",
       "64755         3  0.000000  0.0  0.000000  0.684672  1.042818  0.0  0.051466   \n",
       "43956         4  0.000000  0.0  0.000000  0.692414  0.909816  0.0  0.000000   \n",
       "...         ...       ...  ...       ...       ...       ...  ...       ...   \n",
       "37194         4  0.019845  0.0  0.016161  0.964591  1.173508  0.0  0.140219   \n",
       "6265          1  0.000000  0.0  0.000000  0.952198  1.008503  0.0  0.337828   \n",
       "54886         3  0.041388  0.0  0.001812  0.848586  1.039537  0.0  0.000000   \n",
       "860           1  0.000000  0.0  0.000000  0.818041  1.054909  0.0  0.144149   \n",
       "15795         2  0.000000  0.0  0.000000  0.736923  1.005885  0.0  0.015566   \n",
       "\n",
       "              7         8  ...  502       503  504       505       506  \\\n",
       "33510  0.501675  0.000000  ...  0.0  0.362035  0.0  0.467673  1.165974   \n",
       "12486  0.484815  0.039116  ...  0.0  0.306591  0.0  0.508091  1.130859   \n",
       "41888  0.575311  0.098381  ...  0.0  0.417813  0.0  0.472730  1.122290   \n",
       "64755  0.603697  0.000000  ...  0.0  0.461360  0.0  0.470313  1.071408   \n",
       "43956  0.633609  0.042000  ...  0.0  0.353771  0.0  0.474872  1.126492   \n",
       "...         ...       ...  ...  ...       ...  ...       ...       ...   \n",
       "37194  0.314867  0.050530  ...  0.0  0.427887  0.0  0.472412  1.183986   \n",
       "6265   0.406006  0.035491  ...  0.0  0.436505  0.0  0.459295  1.307488   \n",
       "54886  0.502696  0.079170  ...  0.0  0.310190  0.0  0.459634  1.081609   \n",
       "860    0.560007  0.000000  ...  0.0  0.480492  0.0  0.413958  1.213924   \n",
       "15795  0.598949  0.164870  ...  0.0  0.448563  0.0  0.563077  1.221669   \n",
       "\n",
       "            507  508       509       510       511  \n",
       "33510  1.293850  0.0  2.014301  1.277717  0.469044  \n",
       "12486  1.194992  0.0  1.950154  1.215159  0.431288  \n",
       "41888  1.296171  0.0  1.944820  1.318709  0.374003  \n",
       "64755  1.411013  0.0  1.844043  1.418078  0.320643  \n",
       "43956  1.340509  0.0  1.955878  1.339561  0.333649  \n",
       "...         ...  ...       ...       ...       ...  \n",
       "37194  1.249412  0.0  1.956842  1.329571  0.390479  \n",
       "6265   1.178103  0.0  1.797342  1.186611  0.166288  \n",
       "54886  1.255658  0.0  1.942527  1.300690  0.468613  \n",
       "860    1.369703  0.0  1.892915  1.289477  0.283148  \n",
       "15795  1.255569  0.0  1.987585  1.197671  0.277812  \n",
       "\n",
       "[56170 rows x 513 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb98a7d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost model for attr_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:48:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for attr_1: 0.4748\n",
      "\n",
      "Training XGBoost model for attr_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:50:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for attr_2: 0.6648\n",
      "\n",
      "Training XGBoost model for attr_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:51:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for attr_3: 0.7426\n",
      "\n",
      "Training XGBoost model for attr_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:52:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for attr_4: 0.6753\n",
      "\n",
      "Training XGBoost model for attr_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:54:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for attr_5: 0.6796\n",
      "\n",
      "Training XGBoost model for attr_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:55:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for attr_6: 0.6724\n",
      "\n",
      "Training XGBoost model for attr_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:56:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for attr_7: 0.6572\n",
      "\n",
      "Training XGBoost model for attr_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:57:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for attr_8: 0.6926\n",
      "\n",
      "Training XGBoost model for attr_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:58:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for attr_9: 0.7707\n",
      "\n",
      "Training XGBoost model for attr_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghosl\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:59:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for attr_10: 0.7420\n",
      "\n",
      "Average F1 Score across all attributes: 0.6772\n"
     ]
    }
   ],
   "source": [
    "# Train an XGBoost model for each attribute\n",
    "models = {}\n",
    "f1_scores = []\n",
    "\n",
    "for i, attr in enumerate(y_attributes.columns):\n",
    "    print(f\"\\nTraining XGBoost model for {attr}\")\n",
    "    \n",
    "    y_train = y_train_attrs[attr]\n",
    "    y_val = y_val_attrs[attr]\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=len(np.unique(y_train)),\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    models[attr] = model\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    print(f\"F1 Score for {attr}: {f1:.4f}\")\n",
    "\n",
    "# Calculate and print average F1 score\n",
    "average_f1_score = np.mean(f1_scores)\n",
    "print(f\"\\nAverage F1 Score across all attributes: {average_f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d49f4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_path = 'test_image_features_multilayer.csv'\n",
    "if not os.path.exists(test_features_path):\n",
    "    test_img_features_df = extract_image_features_batch(test_df, 'test_images', test_features_path, feature_extractor)\n",
    "else:\n",
    "    test_img_features_df = pd.read_csv(test_features_path, index_col=0)\n",
    "test_df = test_df.merge(test_img_features_df, left_on='id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b94ac90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data and make predictions\n",
    "test_df['Category'] = test_df['Category'].astype('category').cat.codes\n",
    "X_test_final = test_df.drop(columns=['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b56c33bd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660861</td>\n",
       "      <td>0.916551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.705858</td>\n",
       "      <td>0.113085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597402</td>\n",
       "      <td>1.171146</td>\n",
       "      <td>1.415220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.944925</td>\n",
       "      <td>1.313812</td>\n",
       "      <td>0.207337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.776056</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>1.171969</td>\n",
       "      <td>1.371264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.930488</td>\n",
       "      <td>1.276301</td>\n",
       "      <td>0.414265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.722993</td>\n",
       "      <td>0.931115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.607304</td>\n",
       "      <td>0.030614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531207</td>\n",
       "      <td>1.123717</td>\n",
       "      <td>1.363787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.926084</td>\n",
       "      <td>1.337384</td>\n",
       "      <td>0.325754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047061</td>\n",
       "      <td>0.797601</td>\n",
       "      <td>1.088529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182216</td>\n",
       "      <td>0.243571</td>\n",
       "      <td>0.038832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452084</td>\n",
       "      <td>1.076712</td>\n",
       "      <td>1.180552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.680155</td>\n",
       "      <td>1.175131</td>\n",
       "      <td>0.460504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781933</td>\n",
       "      <td>1.039646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199993</td>\n",
       "      <td>0.486625</td>\n",
       "      <td>0.088393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387622</td>\n",
       "      <td>1.084767</td>\n",
       "      <td>1.231349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.836759</td>\n",
       "      <td>1.064677</td>\n",
       "      <td>0.325395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30200</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.646956</td>\n",
       "      <td>0.896937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.682525</td>\n",
       "      <td>0.023387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520822</td>\n",
       "      <td>1.113395</td>\n",
       "      <td>1.365531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.984479</td>\n",
       "      <td>1.317122</td>\n",
       "      <td>0.434052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30201</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.721103</td>\n",
       "      <td>0.955345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600525</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503209</td>\n",
       "      <td>1.075390</td>\n",
       "      <td>1.245884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.962016</td>\n",
       "      <td>1.298716</td>\n",
       "      <td>0.410173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30202</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738599</td>\n",
       "      <td>1.005875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598262</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487084</td>\n",
       "      <td>1.099078</td>\n",
       "      <td>1.362642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.965711</td>\n",
       "      <td>1.379475</td>\n",
       "      <td>0.450563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30203</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832554</td>\n",
       "      <td>1.043268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486623</td>\n",
       "      <td>0.014042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430027</td>\n",
       "      <td>1.130291</td>\n",
       "      <td>1.344029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.942652</td>\n",
       "      <td>1.281846</td>\n",
       "      <td>0.485166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30204</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.746580</td>\n",
       "      <td>1.056820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036093</td>\n",
       "      <td>0.620245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503210</td>\n",
       "      <td>1.087145</td>\n",
       "      <td>1.421515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.905606</td>\n",
       "      <td>1.382870</td>\n",
       "      <td>0.353294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30205 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category    0    1         2         3         4    5         6  \\\n",
       "0             1  0.0  0.0  0.000000  0.660861  0.916551  0.0  0.127660   \n",
       "1             1  0.0  0.0  0.000000  0.776056  0.979775  0.0  0.000000   \n",
       "2             1  0.0  0.0  0.000000  0.722993  0.931115  0.0  0.000000   \n",
       "3             1  0.0  0.0  0.047061  0.797601  1.088529  0.0  0.182216   \n",
       "4             1  0.0  0.0  0.000000  0.781933  1.039646  0.0  0.199993   \n",
       "...         ...  ...  ...       ...       ...       ...  ...       ...   \n",
       "30200         3  0.0  0.0  0.000000  0.646956  0.896937  0.0  0.000000   \n",
       "30201         3  0.0  0.0  0.000000  0.721103  0.955345  0.0  0.000000   \n",
       "30202         3  0.0  0.0  0.000000  0.738599  1.005875  0.0  0.000000   \n",
       "30203         3  0.0  0.0  0.000000  0.832554  1.043268  0.0  0.000000   \n",
       "30204         3  0.0  0.0  0.000000  0.746580  1.056820  0.0  0.036093   \n",
       "\n",
       "              7         8  ...  502       503  504       505       506  \\\n",
       "0      0.705858  0.113085  ...  0.0  0.670076  0.0  0.597402  1.171146   \n",
       "1      0.514789  0.000000  ...  0.0  0.346264  0.0  0.435001  1.171969   \n",
       "2      0.607304  0.030614  ...  0.0  0.413042  0.0  0.531207  1.123717   \n",
       "3      0.243571  0.038832  ...  0.0  0.423012  0.0  0.452084  1.076712   \n",
       "4      0.486625  0.088393  ...  0.0  0.679748  0.0  0.387622  1.084767   \n",
       "...         ...       ...  ...  ...       ...  ...       ...       ...   \n",
       "30200  0.682525  0.023387  ...  0.0  0.224227  0.0  0.520822  1.113395   \n",
       "30201  0.600525  0.013362  ...  0.0  0.260498  0.0  0.503209  1.075390   \n",
       "30202  0.598262  0.013731  ...  0.0  0.337793  0.0  0.487084  1.099078   \n",
       "30203  0.486623  0.014042  ...  0.0  0.421896  0.0  0.430027  1.130291   \n",
       "30204  0.620245  0.000000  ...  0.0  0.444962  0.0  0.503210  1.087145   \n",
       "\n",
       "            507  508       509       510       511  \n",
       "0      1.415220  0.0  1.944925  1.313812  0.207337  \n",
       "1      1.371264  0.0  1.930488  1.276301  0.414265  \n",
       "2      1.363787  0.0  1.926084  1.337384  0.325754  \n",
       "3      1.180552  0.0  1.680155  1.175131  0.460504  \n",
       "4      1.231349  0.0  1.836759  1.064677  0.325395  \n",
       "...         ...  ...       ...       ...       ...  \n",
       "30200  1.365531  0.0  1.984479  1.317122  0.434052  \n",
       "30201  1.245884  0.0  1.962016  1.298716  0.410173  \n",
       "30202  1.362642  0.0  1.965711  1.379475  0.450563  \n",
       "30203  1.344029  0.0  1.942652  1.281846  0.485166  \n",
       "30204  1.421515  0.0  1.905606  1.382870  0.353294  \n",
       "\n",
       "[30205 rows x 513 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48be90fe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for attr_1\n",
      "Making predictions for attr_2\n",
      "Making predictions for attr_3\n",
      "Making predictions for attr_4\n",
      "Making predictions for attr_5\n",
      "Making predictions for attr_6\n",
      "Making predictions for attr_7\n",
      "Making predictions for attr_8\n",
      "Making predictions for attr_9\n",
      "Making predictions for attr_10\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for i, (attr, model) in enumerate(models.items()):\n",
    "    print(f\"Making predictions for {attr}\")\n",
    "    predictions[attr] = model.predict(X_test_final)\n",
    "\n",
    "# Decode predictions back to original label values\n",
    "predicted_attributes = {\n",
    "    attr: encoders[attr].inverse_transform(predictions[attr])\n",
    "    for attr in y_attributes.columns\n",
    "}\n",
    "predicted_df = pd.DataFrame(predicted_attributes)\n",
    "\n",
    "# Concatenate predictions with 'id' and 'Category' columns for submission\n",
    "test_predictions = pd.concat([test_df[['id', 'Category']], predicted_df], axis=1)\n",
    "\n",
    "# Map encoded 'Category' values back to original labels\n",
    "original_test_df = pd.read_csv('test.csv')\n",
    "category_mapping = dict(enumerate(original_test_df['Category'].astype('category').cat.categories))\n",
    "test_predictions['Category'] = test_predictions['Category'].map(category_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2843096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_finetuned_rs_x.csv file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to CSV\n",
    "test_predictions.to_csv('submission_ft_rnt_x_516_1.csv', index=False)\n",
    "print(\"submission_finetuned_rs_x.csv file saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a766c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
